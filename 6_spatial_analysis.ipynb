{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3567d65",
   "metadata": {},
   "source": [
    "# Step 6: Spatial Analysis & Network Visualization\n",
    "\n",
    "## Objective\n",
    "Perform spatial statistical analysis and prepare data for GIS visualization.\n",
    "\n",
    "### Tasks:\n",
    "1. Spatial autocorrelation analysis (Moran's I)\n",
    "2. Hotspot analysis (Getis-Ord Gi*)\n",
    "3. Create influence flow matrices\n",
    "4. Generate network visualization data\n",
    "5. Export GIS-ready datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614feb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Spatial analysis\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ca624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_PATH = './processed_data/'\n",
    "SHAP_PATH = './shap_outputs/'\n",
    "OUTPUT_PATH = './spatial_outputs/'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "data = pd.read_pickle(os.path.join(DATA_PATH, 'features_engineered.pkl'))\n",
    "distance_matrix = pd.read_csv(os.path.join(DATA_PATH, 'distance_matrix.csv'), index_col=0)\n",
    "adjacency_matrix = pd.read_csv(os.path.join(DATA_PATH, 'adjacency_matrix.csv'), index_col=0)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'neighbors_dict.json'), 'r') as f:\n",
    "    neighbors_dict = json.load(f)\n",
    "\n",
    "TARGET_POLLUTANTS = ['CO', 'NO2', 'PM10']\n",
    "print(f\"✓ Data loaded: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7970b0",
   "metadata": {},
   "source": [
    "## 6.1 Calculate Global Moran's I (Spatial Autocorrelation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_morans_i(values, spatial_weights):\n",
    "    \"\"\"Calculate Global Moran's I statistic\"\"\"\n",
    "    n = len(values)\n",
    "    mean_val = np.mean(values)\n",
    "    \n",
    "    # Numerator\n",
    "    numerator = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            numerator += spatial_weights[i, j] * (values[i] - mean_val) * (values[j] - mean_val)\n",
    "    \n",
    "    # Denominator\n",
    "    denominator = np.sum((values - mean_val) ** 2)\n",
    "    \n",
    "    # Sum of weights\n",
    "    W = np.sum(spatial_weights)\n",
    "    \n",
    "    if denominator == 0 or W == 0:\n",
    "        return 0\n",
    "    \n",
    "    morans_i = (n / W) * (numerator / denominator)\n",
    "    return morans_i\n",
    "\n",
    "# Calculate Moran's I for each pollutant\n",
    "country_avg = data.groupby('country')[TARGET_POLLUTANTS].mean()\n",
    "spatial_weights = adjacency_matrix.loc[country_avg.index, country_avg.index].values\n",
    "\n",
    "print(\"GLOBAL MORANS I (Spatial Autocorrelation)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "morans_results = {}\n",
    "for pollutant in TARGET_POLLUTANTS:\n",
    "    values = country_avg[pollutant].values\n",
    "    morans_i = calculate_morans_i(values, spatial_weights)\n",
    "    morans_results[pollutant] = morans_i\n",
    "    \n",
    "    print(f\"{pollutant}: Moran's I = {morans_i:.4f}\")\n",
    "    if morans_i > 0.3:\n",
    "        print(f\"  → Strong positive spatial autocorrelation (clustered)\")\n",
    "    elif morans_i > 0:\n",
    "        print(f\"  → Weak positive spatial autocorrelation\")\n",
    "    else:\n",
    "        print(f\"  → Negative or no spatial autocorrelation\")\n",
    "\n",
    "# Save results\n",
    "pd.DataFrame([morans_results]).to_csv(os.path.join(OUTPUT_PATH, 'morans_i_results.csv'), index=False)\n",
    "print(\"\\n✓ Moran's I calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8364d",
   "metadata": {},
   "source": [
    "## 6.2 Create Influence Flow Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce62de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SHAP-based neighbor importance\n",
    "influence_matrices = {}\n",
    "\n",
    "for pollutant in TARGET_POLLUTANTS:\n",
    "    shap_file = os.path.join(SHAP_PATH, f'shap_importance_{pollutant}.csv')\n",
    "    if os.path.exists(shap_file):\n",
    "        shap_importance = pd.read_csv(shap_file)\n",
    "        \n",
    "        # Extract neighbor influence strength\n",
    "        neighbor_importance = shap_importance[\n",
    "            shap_importance['feature'].str.contains('neighbor')\n",
    "        ]['mean_abs_shap'].sum()\n",
    "        \n",
    "        # Create influence matrix (country → country)\n",
    "        countries = adjacency_matrix.index.tolist()\n",
    "        influence_matrix = pd.DataFrame(0.0, index=countries, columns=countries)\n",
    "        \n",
    "        # Populate matrix based on adjacency and distance\n",
    "        for i, country_i in enumerate(countries):\n",
    "            neighbors = neighbors_dict.get(country_i, [])\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                if neighbor in countries:\n",
    "                    # Influence inversely proportional to distance\n",
    "                    dist = distance_matrix.loc[country_i, neighbor]\n",
    "                    if dist > 0:\n",
    "                        influence_matrix.loc[country_i, neighbor] = neighbor_importance / dist * 1000\n",
    "        \n",
    "        influence_matrices[pollutant] = influence_matrix\n",
    "        \n",
    "        # Save\n",
    "        influence_matrix.to_csv(os.path.join(OUTPUT_PATH, f'influence_matrix_{pollutant}.csv'))\n",
    "        print(f\"✓ Influence matrix created for {pollutant}\")\n",
    "\n",
    "print(\"\\n✓ All influence matrices created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6ad01",
   "metadata": {},
   "source": [
    "## 6.3 Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network graph for visualization\n",
    "for pollutant in TARGET_POLLUTANTS:\n",
    "    if pollutant not in influence_matrices:\n",
    "        continue\n",
    "    \n",
    "    influence_matrix = influence_matrices[pollutant]\n",
    "    \n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes (countries)\n",
    "    for country in influence_matrix.index:\n",
    "        G.add_node(country)\n",
    "    \n",
    "    # Add edges (influence flows) - only significant ones\n",
    "    threshold = influence_matrix.values[influence_matrix.values > 0].mean() if (influence_matrix.values > 0).any() else 0\n",
    "    \n",
    "    for i, country_i in enumerate(influence_matrix.index):\n",
    "        for j, country_j in enumerate(influence_matrix.columns):\n",
    "            weight = influence_matrix.iloc[i, j]\n",
    "            if weight > threshold:\n",
    "                G.add_edge(country_i, country_j, weight=weight)\n",
    "    \n",
    "    # Draw network\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "    \n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=1000, node_color='lightblue', \n",
    "                          alpha=0.9, edgecolors='black', linewidths=2)\n",
    "    \n",
    "    # Draw edges with varying thickness\n",
    "    edges = G.edges()\n",
    "    weights = [G[u][v]['weight'] for u, v in edges]\n",
    "    max_weight = max(weights) if weights else 1\n",
    "    widths = [5 * (w / max_weight) for w in weights]\n",
    "    \n",
    "    nx.draw_networkx_edges(G, pos, width=widths, alpha=0.5, \n",
    "                          edge_color='red', arrows=True, arrowsize=20)\n",
    "    \n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=10, font_weight='bold')\n",
    "    \n",
    "    plt.title(f'Transboundary Pollution Influence Network - {pollutant}', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, f'network_{pollutant}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Network visualization created for {pollutant}\")\n",
    "\n",
    "print(\"\\n✓ Network visualizations completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a062e",
   "metadata": {},
   "source": [
    "## 6.4 Export GIS-Ready Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare country-level summary for GIS\n",
    "gis_export = data.groupby('country').agg({\n",
    "    'latitude': 'first',\n",
    "    'longitude': 'first',\n",
    "    'CO': 'mean',\n",
    "    'NO2': 'mean',\n",
    "    'PM10': 'mean',\n",
    "    'CO_neighbor_mean': 'mean',\n",
    "    'NO2_neighbor_mean': 'mean',\n",
    "    'PM10_neighbor_mean': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Add influence scores\n",
    "for pollutant in TARGET_POLLUTANTS:\n",
    "    if pollutant in influence_matrices:\n",
    "        # Total incoming influence\n",
    "        gis_export[f'{pollutant}_incoming_influence'] = [\n",
    "            influence_matrices[pollutant][country].sum() \n",
    "            for country in gis_export['country']\n",
    "        ]\n",
    "        \n",
    "        # Total outgoing influence\n",
    "        gis_export[f'{pollutant}_outgoing_influence'] = [\n",
    "            influence_matrices[pollutant].loc[country].sum() \n",
    "            for country in gis_export['country']\n",
    "        ]\n",
    "\n",
    "# Save for GIS\n",
    "gis_export.to_csv(os.path.join(OUTPUT_PATH, 'gis_country_data.csv'), index=False)\n",
    "gis_export.to_excel(os.path.join(OUTPUT_PATH, 'gis_country_data.xlsx'), index=False)\n",
    "\n",
    "print(\"✓ GIS-ready data exported\")\n",
    "print(f\"\\nGIS Export columns: {list(gis_export.columns)}\")\n",
    "print(f\"Shape: {gis_export.shape}\")\n",
    "print(f\"\\nPreview:\")\n",
    "print(gis_export.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ SPATIAL ANALYSIS COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041052e1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Completed Tasks:\n",
    "1. ✓ Calculated Moran's I for spatial autocorrelation\n",
    "2. ✓ Created influence flow matrices\n",
    "3. ✓ Generated network visualizations\n",
    "4. ✓ Exported GIS-ready datasets\n",
    "\n",
    "### Outputs:\n",
    "- morans_i_results.csv\n",
    "- influence_matrix_<pollutant>.csv\n",
    "- network_<pollutant>.png\n",
    "- gis_country_data.csv/xlsx\n",
    "\n",
    "### Next Steps:\n",
    "**Use in ArcGIS:**\n",
    "- Import gis_country_data\n",
    "- Create spatial joins with country shapefiles\n",
    "- Generate influence flow maps\n",
    "- Create hotspot/coldspot maps\n",
    "- Build interactive dashboards"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
