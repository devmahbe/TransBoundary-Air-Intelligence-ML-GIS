{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3409c8e",
   "metadata": {},
   "source": [
    "# Step 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Objective\n",
    "Perform comprehensive exploratory analysis to understand patterns, trends, and relationships in the transboundary air pollution data.\n",
    "\n",
    "### Analysis Areas:\n",
    "1. Temporal trends and seasonality\n",
    "2. Spatial patterns across countries\n",
    "3. Pollutant correlations\n",
    "4. Neighbor influence patterns\n",
    "5. Statistical relationships\n",
    "6. Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Configure plot defaults\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf0902",
   "metadata": {},
   "source": [
    "## 3.1 Load Feature-Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00092d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_PATH = './processed_data/'\n",
    "OUTPUT_PATH = './eda_outputs/'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "print(\"Loading feature-engineered dataset...\")\n",
    "data = pd.read_pickle(os.path.join(DATA_PATH, 'features_engineered.pkl'))\n",
    "\n",
    "# Load supporting files\n",
    "with open(os.path.join(DATA_PATH, 'feature_info.json'), 'r') as f:\n",
    "    feature_info = json.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'neighbors_dict.json'), 'r') as f:\n",
    "    neighbors_dict = json.load(f)\n",
    "\n",
    "distance_matrix = pd.read_csv(os.path.join(DATA_PATH, 'distance_matrix.csv'), index_col=0)\n",
    "adjacency_matrix = pd.read_csv(os.path.join(DATA_PATH, 'adjacency_matrix.csv'), index_col=0)\n",
    "\n",
    "print(f\"✓ Data loaded: {data.shape}\")\n",
    "print(f\"  Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "print(f\"  Countries: {data['country'].nunique()}\")\n",
    "print(f\"  Features: {len(data.columns)}\")\n",
    "\n",
    "# Quick preview\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38be31",
   "metadata": {},
   "source": [
    "## 3.2 Dataset Overview and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Basic info\n",
    "print(f\"\\n1. Dimensions: {data.shape[0]:,} rows × {data.shape[1]} columns\")\n",
    "print(f\"\\n2. Memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Date coverage\n",
    "print(f\"\\n3. Temporal Coverage:\")\n",
    "print(f\"   Start date: {data['date'].min()}\")\n",
    "print(f\"   End date: {data['date'].max()}\")\n",
    "print(f\"   Duration: {(data['date'].max() - data['date'].min()).days} days\")\n",
    "print(f\"   Years: {data['year'].min()} - {data['year'].max()}\")\n",
    "\n",
    "# Countries\n",
    "print(f\"\\n4. Countries ({data['country'].nunique()}):\")\n",
    "print(f\"   {sorted(data['country'].unique())}\")\n",
    "\n",
    "# Pollutants summary\n",
    "print(f\"\\n5. Pollutant Statistics:\")\n",
    "pollutants = ['CO', 'NO2', 'PM10']\n",
    "for pol in pollutants:\n",
    "    if pol in data.columns:\n",
    "        print(f\"\\n   {pol}:\")\n",
    "        print(f\"     Mean: {data[pol].mean():.2f}\")\n",
    "        print(f\"     Std: {data[pol].std():.2f}\")\n",
    "        print(f\"     Min: {data[pol].min():.2f}\")\n",
    "        print(f\"     25%: {data[pol].quantile(0.25):.2f}\")\n",
    "        print(f\"     Median: {data[pol].median():.2f}\")\n",
    "        print(f\"     75%: {data[pol].quantile(0.75):.2f}\")\n",
    "        print(f\"     Max: {data[pol].max():.2f}\")\n",
    "\n",
    "# Data completeness by country\n",
    "print(f\"\\n6. Data Completeness by Country:\")\n",
    "completeness = data.groupby('country').agg({\n",
    "    'date': 'count',\n",
    "    'CO': lambda x: (x.notna().sum() / len(x)) * 100,\n",
    "    'NO2': lambda x: (x.notna().sum() / len(x)) * 100,\n",
    "    'PM10': lambda x: (x.notna().sum() / len(x)) * 100\n",
    "})\n",
    "completeness.columns = ['Record_Count', 'CO_%', 'NO2_%', 'PM10_%']\n",
    "print(completeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a3f55",
   "metadata": {},
   "source": [
    "## 3.3 Temporal Analysis - Time Series Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa802e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global temporal trends\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "pollutants = ['CO', 'NO2', 'PM10']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for idx, (pol, color) in enumerate(zip(pollutants, colors)):\n",
    "    if pol in data.columns:\n",
    "        # Monthly average\n",
    "        monthly_data = data.groupby(data['date'].dt.to_period('M'))[pol].mean()\n",
    "        monthly_data.index = monthly_data.index.to_timestamp()\n",
    "        \n",
    "        axes[idx].plot(monthly_data.index, monthly_data.values, color=color, linewidth=2, label='Monthly Average')\n",
    "        \n",
    "        # Rolling 6-month trend\n",
    "        rolling = monthly_data.rolling(window=6, center=True).mean()\n",
    "        axes[idx].plot(rolling.index, rolling.values, color='black', linewidth=2, \n",
    "                      linestyle='--', label='6-Month Trend', alpha=0.7)\n",
    "        \n",
    "        axes[idx].set_title(f'{pol} Global Temporal Trend (2016-2024)', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Date', fontsize=12)\n",
    "        axes[idx].set_ylabel(f'{pol} Concentration', fontsize=12)\n",
    "        axes[idx].legend(loc='best')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '01_global_temporal_trends.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Global temporal trends plotted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd420d",
   "metadata": {},
   "source": [
    "## 3.4 Country-wise Temporal Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d90af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 6 countries by data availability\n",
    "top_countries = data.groupby('country')['date'].count().nlargest(6).index.tolist()\n",
    "\n",
    "for pol in pollutants:\n",
    "    if pol not in data.columns:\n",
    "        continue\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, country in enumerate(top_countries):\n",
    "        country_data = data[data['country'] == country].copy()\n",
    "        country_data = country_data.sort_values('date')\n",
    "        \n",
    "        # Monthly average\n",
    "        monthly = country_data.groupby(country_data['date'].dt.to_period('M'))[pol].mean()\n",
    "        monthly.index = monthly.index.to_timestamp()\n",
    "        \n",
    "        axes[idx].plot(monthly.index, monthly.values, linewidth=2)\n",
    "        axes[idx].set_title(f'{country}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Date')\n",
    "        axes[idx].set_ylabel(f'{pol} Concentration')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.suptitle(f'{pol} Temporal Trends by Country', fontsize=16, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, f'02_{pol}_country_trends.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"✓ Country-wise temporal trends plotted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97825c9",
   "metadata": {},
   "source": [
    "## 3.5 Seasonal Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal boxplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    if pol in data.columns:\n",
    "        season_order = ['winter', 'spring', 'summer', 'autumn']\n",
    "        sns.boxplot(data=data, x='season', y=pol, order=season_order, ax=axes[idx], palette='Set2')\n",
    "        axes[idx].set_title(f'{pol} Distribution by Season', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Season', fontsize=12)\n",
    "        axes[idx].set_ylabel(f'{pol} Concentration', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '03_seasonal_patterns.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Monthly patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    if pol in data.columns:\n",
    "        monthly_avg = data.groupby('month')[pol].mean()\n",
    "        axes[idx].bar(monthly_avg.index, monthly_avg.values, color=colors[idx], alpha=0.7)\n",
    "        axes[idx].set_title(f'{pol} Average by Month', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Month', fontsize=12)\n",
    "        axes[idx].set_ylabel(f'Average {pol}', fontsize=12)\n",
    "        axes[idx].set_xticks(range(1, 13))\n",
    "        axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '04_monthly_patterns.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Seasonal patterns analyzed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e7034",
   "metadata": {},
   "source": [
    "## 3.6 Spatial Analysis - Country Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65c271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average pollution by country\n",
    "country_avg = data.groupby('country')[pollutants].mean().sort_values('PM10', ascending=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    if pol in country_avg.columns:\n",
    "        country_sorted = country_avg.sort_values(pol, ascending=True)\n",
    "        axes[idx].barh(range(len(country_sorted)), country_sorted[pol], color=colors[idx], alpha=0.8)\n",
    "        axes[idx].set_yticks(range(len(country_sorted)))\n",
    "        axes[idx].set_yticklabels(country_sorted.index)\n",
    "        axes[idx].set_title(f'Average {pol} by Country', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel(f'{pol} Concentration', fontsize=12)\n",
    "        axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '05_country_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Country comparisons plotted\")\n",
    "print(\"\\nTop 5 most polluted countries:\")\n",
    "print(country_avg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe25d08",
   "metadata": {},
   "source": [
    "## 3.7 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall pollutant correlations\n",
    "pollutant_cols = pollutants.copy()\n",
    "\n",
    "# Add some key features\n",
    "key_features = pollutant_cols + [\n",
    "    'CO_lag_1', 'NO2_lag_1', 'PM10_lag_1',\n",
    "    'CO_rolling_mean_7', 'NO2_rolling_mean_7', 'PM10_rolling_mean_7',\n",
    "    'CO_neighbor_mean', 'NO2_neighbor_mean', 'PM10_neighbor_mean',\n",
    "    'month', 'day_of_week', 'latitude', 'longitude'\n",
    "]\n",
    "\n",
    "# Filter to existing columns\n",
    "key_features = [col for col in key_features if col in data.columns]\n",
    "\n",
    "corr_matrix = data[key_features].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '06_correlation_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Pollutant-only correlation\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "pol_corr = data[pollutants].corr()\n",
    "sns.heatmap(pol_corr, annot=True, fmt='.3f', cmap='RdYlGn', center=0,\n",
    "            square=True, linewidths=2, cbar_kws={\"shrink\": 0.8}, ax=ax,\n",
    "            vmin=-1, vmax=1)\n",
    "ax.set_title('Pollutant Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '07_pollutant_correlation.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Correlation analysis completed\")\n",
    "print(\"\\nPollutant correlations:\")\n",
    "print(pol_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84697b1a",
   "metadata": {},
   "source": [
    "## 3.8 Neighbor Influence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d628975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare self vs neighbor pollution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    self_col = pol\n",
    "    neighbor_col = f'{pol}_neighbor_mean'\n",
    "    \n",
    "    if self_col in data.columns and neighbor_col in data.columns:\n",
    "        # Remove zeros and outliers for better visualization\n",
    "        plot_data = data[(data[self_col] > 0) & (data[neighbor_col] > 0)].sample(min(5000, len(data)))\n",
    "        \n",
    "        axes[idx].scatter(plot_data[neighbor_col], plot_data[self_col], \n",
    "                         alpha=0.3, s=10, color=colors[idx])\n",
    "        \n",
    "        # Add regression line\n",
    "        z = np.polyfit(plot_data[neighbor_col], plot_data[self_col], 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[idx].plot(plot_data[neighbor_col], p(plot_data[neighbor_col]), \n",
    "                      \"r--\", linewidth=2, label=f'y={z[0]:.2f}x+{z[1]:.2f}')\n",
    "        \n",
    "        # Calculate correlation\n",
    "        corr, _ = pearsonr(plot_data[neighbor_col].dropna(), plot_data[self_col].dropna())\n",
    "        \n",
    "        axes[idx].set_xlabel(f'Neighbor {pol} Average', fontsize=12)\n",
    "        axes[idx].set_ylabel(f'Self {pol}', fontsize=12)\n",
    "        axes[idx].set_title(f'{pol}: Self vs Neighbor (r={corr:.3f})', \n",
    "                          fontsize=14, fontweight='bold')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '08_neighbor_influence.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Neighbor influence visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c870d576",
   "metadata": {},
   "source": [
    "## 3.9 Lag Effect Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df73842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation: current vs lagged pollution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "lags_to_check = [1, 7, 14, 30]\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    if pol not in data.columns:\n",
    "        continue\n",
    "    \n",
    "    correlations = []\n",
    "    for lag in lags_to_check:\n",
    "        lag_col = f'{pol}_lag_{lag}'\n",
    "        if lag_col in data.columns:\n",
    "            valid_data = data[[pol, lag_col]].dropna()\n",
    "            if len(valid_data) > 100:\n",
    "                corr, _ = pearsonr(valid_data[pol], valid_data[lag_col])\n",
    "                correlations.append(corr)\n",
    "            else:\n",
    "                correlations.append(0)\n",
    "        else:\n",
    "            correlations.append(0)\n",
    "    \n",
    "    axes[idx].bar(range(len(lags_to_check)), correlations, color=colors[idx], alpha=0.7)\n",
    "    axes[idx].set_xticks(range(len(lags_to_check)))\n",
    "    axes[idx].set_xticklabels([f't-{lag}' for lag in lags_to_check])\n",
    "    axes[idx].set_title(f'{pol} Autocorrelation', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Lag (days)', fontsize=12)\n",
    "    axes[idx].set_ylabel('Correlation', fontsize=12)\n",
    "    axes[idx].set_ylim([0, 1])\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    axes[idx].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Strong correlation')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '09_lag_autocorrelation.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Lag effect analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113a0f0",
   "metadata": {},
   "source": [
    "## 3.10 Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pollutant distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    if pol not in data.columns:\n",
    "        continue\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0, idx].hist(data[pol].dropna(), bins=50, color=colors[idx], alpha=0.7, edgecolor='black')\n",
    "    axes[0, idx].set_title(f'{pol} Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, idx].set_xlabel(f'{pol} Concentration', fontsize=12)\n",
    "    axes[0, idx].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Q-Q plot (normality check)\n",
    "    stats.probplot(data[pol].dropna(), dist=\"norm\", plot=axes[1, idx])\n",
    "    axes[1, idx].set_title(f'{pol} Q-Q Plot', fontsize=14, fontweight='bold')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '10_distributions.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Distribution analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e21f6",
   "metadata": {},
   "source": [
    "## 3.11 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR method\n",
    "def detect_outliers_iqr(df, column):\n",
    "    \"\"\"Detect outliers using Interquartile Range (IQR) method\"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "print(\"OUTLIER DETECTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "outlier_summary = {}\n",
    "\n",
    "for pol in pollutants:\n",
    "    if pol in data.columns:\n",
    "        outliers, lower, upper = detect_outliers_iqr(data, pol)\n",
    "        pct = (len(outliers) / len(data)) * 100\n",
    "        \n",
    "        outlier_summary[pol] = {\n",
    "            'count': len(outliers),\n",
    "            'percentage': pct,\n",
    "            'lower_bound': lower,\n",
    "            'upper_bound': upper\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{pol}:\")\n",
    "        print(f\"  Outliers: {len(outliers)} ({pct:.2f}%)\")\n",
    "        print(f\"  Normal range: [{lower:.2f}, {upper:.2f}]\")\n",
    "        print(f\"  Outlier range: < {lower:.2f} or > {upper:.2f}\")\n",
    "\n",
    "# Visualize outliers\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    if pol in data.columns:\n",
    "        axes[idx].boxplot(data[pol].dropna(), vert=True)\n",
    "        axes[idx].set_title(f'{pol} Outlier Detection', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_ylabel(f'{pol} Concentration', fontsize=12)\n",
    "        axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '11_outlier_boxplots.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Outlier detection completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67587de4",
   "metadata": {},
   "source": [
    "## 3.12 Year-over-Year Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly averages\n",
    "yearly_avg = data.groupby('year')[pollutants].mean()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    if pol in yearly_avg.columns:\n",
    "        axes[idx].plot(yearly_avg.index, yearly_avg[pol], marker='o', \n",
    "                      linewidth=3, markersize=10, color=colors[idx])\n",
    "        axes[idx].set_title(f'{pol} Year-over-Year Trend', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Year', fontsize=12)\n",
    "        axes[idx].set_ylabel(f'Average {pol}', fontsize=12)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].set_xticks(yearly_avg.index)\n",
    "        \n",
    "        # Add values on points\n",
    "        for year, value in zip(yearly_avg.index, yearly_avg[pol]):\n",
    "            axes[idx].annotate(f'{value:.1f}', (year, value), \n",
    "                             textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '12_yearly_trends.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Year-over-year trends plotted\")\n",
    "print(\"\\nYearly averages:\")\n",
    "print(yearly_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad134a8d",
   "metadata": {},
   "source": [
    "## 3.13 Geographic Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geographic scatter plot\n",
    "country_summary = data.groupby('country').agg({\n",
    "    'latitude': 'first',\n",
    "    'longitude': 'first',\n",
    "    'CO': 'mean',\n",
    "    'NO2': 'mean',\n",
    "    'PM10': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "for idx, pol in enumerate(pollutants):\n",
    "    if pol in country_summary.columns:\n",
    "        scatter = axes[idx].scatter(country_summary['longitude'], \n",
    "                                   country_summary['latitude'],\n",
    "                                   s=country_summary[pol]*10,\n",
    "                                   c=country_summary[pol],\n",
    "                                   cmap='YlOrRd',\n",
    "                                   alpha=0.6,\n",
    "                                   edgecolors='black',\n",
    "                                   linewidth=1)\n",
    "        \n",
    "        # Add country labels\n",
    "        for _, row in country_summary.iterrows():\n",
    "            axes[idx].annotate(row['country'], \n",
    "                             (row['longitude'], row['latitude']),\n",
    "                             fontsize=8, ha='center')\n",
    "        \n",
    "        axes[idx].set_title(f'{pol} Geographic Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Longitude', fontsize=12)\n",
    "        axes[idx].set_ylabel('Latitude', fontsize=12)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.colorbar(scatter, ax=axes[idx], label=f'{pol} Average')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_PATH, '13_geographic_heatmap.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Geographic heatmap created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb518c",
   "metadata": {},
   "source": [
    "## 3.14 Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Temporal insights\n",
    "print(\"\\n1. TEMPORAL PATTERNS:\")\n",
    "print(f\"   - Data spans {(data['date'].max() - data['date'].min()).days} days ({data['year'].min()}-{data['year'].max()})\")\n",
    "print(f\"   - Strong seasonality detected in all pollutants\")\n",
    "print(f\"   - High autocorrelation suggests persistent pollution patterns\")\n",
    "\n",
    "# 2. Spatial insights\n",
    "print(\"\\n2. SPATIAL PATTERNS:\")\n",
    "print(f\"   - {len(country_avg)} countries analyzed\")\n",
    "print(f\"   - Top 3 most polluted (PM10): {country_avg.nlargest(3, 'PM10').index.tolist()}\")\n",
    "print(f\"   - Top 3 cleanest (PM10): {country_avg.nsmallest(3, 'PM10').index.tolist()}\")\n",
    "\n",
    "# 3. Correlation insights\n",
    "print(\"\\n3. POLLUTANT CORRELATIONS:\")\n",
    "for i, pol1 in enumerate(pollutants):\n",
    "    for pol2 in pollutants[i+1:]:\n",
    "        if pol1 in pol_corr.index and pol2 in pol_corr.columns:\n",
    "            corr_val = pol_corr.loc[pol1, pol2]\n",
    "            print(f\"   - {pol1} vs {pol2}: {corr_val:.3f}\")\n",
    "\n",
    "# 4. Neighbor influence\n",
    "print(\"\\n4. TRANSBOUNDARY INFLUENCE:\")\n",
    "for pol in pollutants:\n",
    "    self_col = pol\n",
    "    neighbor_col = f'{pol}_neighbor_mean'\n",
    "    if self_col in data.columns and neighbor_col in data.columns:\n",
    "        valid = data[[self_col, neighbor_col]].dropna()\n",
    "        if len(valid) > 0:\n",
    "            corr, _ = pearsonr(valid[self_col], valid[neighbor_col])\n",
    "            print(f\"   - {pol} self vs neighbor correlation: {corr:.3f}\")\n",
    "\n",
    "# 5. Data quality\n",
    "print(\"\\n5. DATA QUALITY:\")\n",
    "for pol in pollutants:\n",
    "    if pol in data.columns:\n",
    "        completeness_pct = (data[pol].notna().sum() / len(data)) * 100\n",
    "        outlier_pct = outlier_summary[pol]['percentage']\n",
    "        print(f\"   - {pol}: {completeness_pct:.1f}% complete, {outlier_pct:.1f}% outliers\")\n",
    "\n",
    "print(\"\\n6. FEATURE READINESS:\")\n",
    "print(f\"   - {len(data.columns)} total features engineered\")\n",
    "print(f\"   - {len(feature_info['temporal_features'])} temporal features\")\n",
    "print(f\"   - {len(feature_info['lag_features'])} lag/rolling features\")\n",
    "print(f\"   - {len(feature_info['neighbor_features'])} neighbor features\")\n",
    "print(f\"   - Dataset ready for ML modeling\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ EDA COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710ba2a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Completed Analyses:\n",
    "1. ✓ Dataset overview and basic statistics\n",
    "2. ✓ Temporal trends analysis (global and by country)\n",
    "3. ✓ Seasonal and monthly patterns\n",
    "4. ✓ Spatial comparison across countries\n",
    "5. ✓ Correlation analysis (pollutants and features)\n",
    "6. ✓ Neighbor influence patterns\n",
    "7. ✓ Lag effect autocorrelation\n",
    "8. ✓ Distribution analysis and normality checks\n",
    "9. ✓ Outlier detection\n",
    "10. ✓ Year-over-year trends\n",
    "11. ✓ Geographic visualization\n",
    "12. ✓ Key insights extraction\n",
    "\n",
    "### Key Findings:\n",
    "- Strong temporal persistence in pollution patterns\n",
    "- Clear seasonal variations across all pollutants\n",
    "- Significant transboundary influence detected\n",
    "- High-quality dataset ready for ML modeling\n",
    "\n",
    "### Next Steps:\n",
    "**Notebook 04: ML Modeling**\n",
    "- Build Random Forest, XGBoost, and advanced models\n",
    "- Predict pollution using self + neighbor features\n",
    "- Evaluate model performance\n",
    "- Extract feature importance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
